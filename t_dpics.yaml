Variables:
    text2video_root: /volumes/macdrive/projects/text2video
    input:
    output:
    curr_line:
    font_size: 90
    font_color: yellow
    text_left: 40
    text_top: 40

TUBE:
    # All output files are located in tmp/dpics folder
    - PATH: {text2video_root}
    # generate news text and background with title
    # outputs: bg_hd_t2.png, news.txt
    - RUN_TUBE: -t GenNewsText
    # adjust background dimension to 1080:1920
    - COMMAND: ffmpeg -y -i tmp/dpics/bg.png -filter:v "scale=1080:1920:force_original_aspect_ratio=increase,crop=1080:1920" tmp/dpics/bg_hd.png
    # write news to picture background
    - RUN_TUBE: -t WriteText    
    # picture to video
    - COMMAND: ffmpeg -y -loop 1 -i {output} -c:v libx264 -t 10 -pix_fmt yuv420p tmp/dpics/bg_video.mp4
    # video to images
    - COMMAND: rm tmp/dpics/*.jpg --continue
    - COMMAND: ffmpeg -y -i tmp/dpics/bg_video.mp4 ./tmp/dpics/img%03d.jpg
    # Generate new video, 
    # outputs: pics_video.mp4
    - RUN_TUBE: -t CropPicsToVideo
    - COMMAND: rm tmp/dpics/*.jpg --continue
    - COMMAND: rm tmp/dpics/bg_news*.png --continue
    # combine the bg_hd_t2.png, pics_video.mp4
    - COMMAND: >
         ffmpeg -y -i tmp/dpics/bg_hd_t2.png -i tmp/dpics/pics_video.mp4 -filter_complex
            "[1]scale=-1:ih-300,colorkey=0x000000:0.2:0.3[v1];[0][v1]overlay=100:300[out]" 
         -map "[out]" tmp/dpics/out.mp4
    - COMMAND: ffplay tmp/dpics/out.mp4

GenNewsText:
    - GET_FILE_KEY_VALUE: -f tmp/dpics/news.yaml
    - COMMAND: python3 s_splitNews.py '{content}' tmp/dpics/news.txt 10
    - COMMAND: ffmpeg -y -i tmp/dpics/bg_backup.png -filter:v "scale=1080:1920:force_original_aspect_ratio=increase,crop=1080:1920" tmp/dpics/bg_hd_t.png
    - COMMAND: >
        ffmpeg -y -i tmp/dpics/bg_hd_t.png -filter_complex
             "drawbox=
                x=0:
                y=120:
                color=yellow@1:
                width=1080:height=150:t=fill,
             drawtext=fontfile='/library/Fonts/Arial Unicode.ttf':
                text='{title}':
                fontcolor=blue:
                fontsize=120:
                x=(w-tw)/2:
                y=140" 
            tmp/dpics/bg_hd_t2.png

WriteText:
    # write news content to background
    - COUNT: -f tmp/dpics/news.txt -v news_count
    - SET_VARIABLE: -n curr_line -v 0 -g
    - SET_VARIABLE: -n fontHeight -v 50 -g
    - SET_VARIABLE: -n input -v tmp/dpics/bg_hd.png -g
    - RUN_TUBE: -t WriteLine -w {curr_line} < {news_count}
WriteLine:
    - SET_VARIABLE: -n input -v {output} --if {output} != '' -g
    - SET_VARIABLE: -n curr_line -v {curr_line} + 1 -g
    - READ_LINE_IN_FILE: -f tmp/dpics/news.txt -n {curr_line} -v line    
    - COMMAND: >
        ffmpeg -y -i {input} -vf "drawtext=fontfile='/library/Fonts/Arial Unicode.ttf':
                text='{line}':fontcolor={font_color}:
                fontsize={font_size}:
                x=(w-tw)/2:
                y={fontHeight}" 
            tmp/dpics/bg_news_hd{curr_line}.png
    - SET_VARIABLE:  -n output -v tmp/dpics/bg_news_hd{curr_line}.png -g      
    - SET_VARIABLE: -n fontHeight -v {fontHeight} + {font_size} -g

CropPicsToVideo:
    - PATH: '{text2video_root}'
    - LIST_FILES: -d tmp/dpics/*.jpg -r tmp/dpics/all_pics.txt -s name
    - SET_VARIABLE: -n curr_line -v 0 -g
    - RUN_TUBE: -t CROP -w {curr_line} < 250
    - COMMAND: ffmpeg -y -r 25 -i tmp/dpics/img%03d_o.jpg tmp/dpics/pics_video.mp4
CROP:
    - SET_VARIABLE: -n curr_line -v {curr_line} + 1 -g
    - READ_LINE_IN_FILE: -f tmp/dpics/all_pics.txt -n {curr_line} -v line
    - SET_VARIABLE: -n line -v "{line}".replace(".jpg","") --if {line} != '' -g
    - COMMAND: ffmpeg -y -i {line}.jpg -filter:v "crop=iw:(1920/250)*{curr_line}:0:0,pad=1080:1920" {line}_o.jpg --if {line} != ''

Notes: >
    # take 1 frame at a given time
    ffmpeg -ss 5 -i input.mp4 -frames:v 1 out.png

    # how to use one picture to build one video for 10 seconds
    ffmpeg -y -loop 1 -i bg00.jpg -c:v libx264 -t 10 -pix_fmt yuv420p -vf scale=1920:1080 out.mp4

    # how to dynamic show an image over a video
    ffmpeg -y -i out1.mp4 -loop 1 -i bg01.jpg -filter_complex "
                [1:v]scale=1920:1080,crop=w=in_w:h='50t':x=0:y=0[v1];
                [0:v][v1]overlay=0:0:shortest=1[out]
                "
            -map "[out]"  out3.mp4

    # how to use min method to scale an image
    ffmpeg -i bg00.jpg -filter:v "scale='min(1920,iw)':'min(1080,ih)'" out.jpg  

    # scale (decrease) and pad
    ffmpeg -i bg00.jpg -filter:v "scale=1920:1080:force_original_aspect_ratio=decrease,pad=1920:1080:-1:-1:color=black" out.jpg

    # scale (increase) and crop
    ffmpeg -i bg00.jpg -filter:v "scale=1920:1080:force_original_aspect_ratio=increase,crop=1920:1080" out.jpg

    # scale increase neighbor
    ffmpeg -i bg00.jpg -filter:v scale=-1:1080 -sws_flags neighbor out.jpg

    # corp first and scale to bigger one 
    ffmpeg -y -i bg99.png -filter_complex "[0]crop=1080/2:1920/2[p1];[p1]scale=-1:1920[out]" -map "[out]" out.png

    # video to images
    ffmpeg -i out.mp4 ./pics/img%03d.jpg

    # crop sequences of images 
    ffmpeg -y -i ./pics/img%03d.jpg -filter:v "crop=iw:ih/10,pad=1920:1080" ./pics/img%03d_o.jpg